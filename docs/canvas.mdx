# Canvas and WebGL

## Canvas
``` js
const canvas = document.querySelector('canvas');
const context = canvas.getContext('2d');
```

### toBlob

``` js
canvas.toBlob(blob => {
  const url = URL.createObjectURL(blob);
}, "image/jpeg", 1) // quality
```

### toDataURL

``` js
const dataUrl = canvas.toDataURL("image/jpeg", 1); // quality
```

### captureStream
获取Canvas的媒体流，从而实现Video预览或者媒体录制的能力。
``` js
const stream = canvas.captureStream();

// 预览能力 
video.srcObject = stream;

// 录制能力
const recorder = new MediaRecorder(stream);
```


### drawImage

Canvas提供了`drawImage`方法将不同的图像源绘制到我们的目标Canvas上，图像源包括Image、Video甚至另一个Canvas对象，以及后文会介绍的ImageBitMap。

``` js
ctx.drawImage(image, 0, 0)
ctx.drawImage(video, 0, 0)
ctx.drawImage(canvas2, 0, 0)
```

`drawImage`函数是个重载函数，有几种不同的用法。（注：下文中的`d`表示目标Canvas Destination，`s`表示图像源头Source）

1. `drawImage(source, dx, dy)`。简单的用法，以`(dx, dy)`为原点绘制目标图像。

2. `drawImage(source, dx, dy, dWidth, dHeight)`。和用法一类似，额外提供了`width`和`height`的参数允许我们调整所绘制的图像的大小，从而实现类似缩放的效果。

3. `drawImage(source, sx, sy, sWidth, sHeight, dx, dy, dWidth, dHeight)`。这个用法调整了参数的顺序，可用来裁剪数据源的部分区域进行绘制。

   ![](https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/drawImage/canvas_drawimage.jpg)



:::info
`drawImage`使用不同的图像源时的行为不同，性能上也略有差异，笔者在M2 Macbook Pro下，将CPU降速6倍下用15000*15000的图片进行性能测试后得出以下结论（例子中图像源已经完全ready）。
> [Demo链接](https://github.com/Messiahhh/canvas-perf-demo)

1. `drawImage(Image)`，主线程API调用很快，渲染线程绘制上屏较慢（将近3秒）。
2. `drawImage(Canvas)`，主线程API调用很快，渲染线程绘制上屏也很快。**推荐**。
3. `drawImage(OffscreenCanvas)`，主线程API调用很慢（将近3秒），渲染线程绘制上屏快。不知道为什么和用例2存在一定的差距，但总的来说需要在主线程缓存虚拟节点的内容的时候，推荐用Canvas而不是OffscreenCanvas。
4. `drawImage(ImageBitmap)`。主线程API调用很快，渲染线程绘制上屏也很快。和用例2差不多，但也需要考虑生成ImageBitMap花费的时间。

在例子2和例子3中，我们需要先通过drawImage把图片绘制到用来缓存的Canvas/OffscreenCanvas上，但我没有立刻同步地把缓存的Canvas绘制到我们的目标Canvas上，而是使用了一个定时器来确保先执行渲染线程，从而保证我们的Canvas图像源本身已经绘制完毕ready了。
此时整体执行顺序如下：`1. 主线程 drawImage(image) -> 2. 渲染线程 把图片绘制到Canvas上 -> 3. 主线程 drawImage(canvas) -> 4. 渲染线程 绘制Canvas到Canvas`。
因此我实际上测量的是3和4的总时长，这也是离屏渲染的常见场景————我已经提前缓存好了Canvas，现在关心的是调用drawImage(canvas)时上屏所需要的时间。

在其他的一些场景下，我们会在主线程调用了`drawImage(image)`后立刻调用`drawImage(canvas)`，相当于我们例子中把定时器去掉的效果。
此时整体的执行顺序如下：`1. 主线程 drawImage(image) -> 2. 主线程 drawImage(canvas) -> 3. 渲染线程`。
那么此时`drawImage(Canvas)`和`drawImage(OffscreenCanvas)`都耗时将近3秒，渲染线程上屏则迅速完成，应该是浏览器内部存在相应的优化。

:::

### getImageData/putImageData

通过`getImageData`可以直接拿到Canvas指定区域对应的原始像素数据。可以通过指定的数学转换实现不同的效果，比如Konva的高斯模糊等滤镜就是通过纯CPU计算实现的。

``` js
const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height)

for (let i = 0; i < imageData.data.length; i += 4) {
  	imageData.data[i] = 255; // red channel
    imageData.data[i + 1] = 0; // green channel
    imageData.data[i + 2] = 255; // blue channel
    imageData.data[i + 3] = 200; // alpha channel
}
ctx.putImageData(imageData, 0, 0)
```

:::caution
需要特别注意的是，`getImageData`和`putImageData`都是非常耗CPU的操作，容易造成长任务。除非我们确实需要对像素做一些操作，否则都应该使用`drawImage`等方法来进行绘制。
:::

:::info GPU/CPU Canvas
默认情况下Canvas的创建和绘制都是在GPU上的（硬件加速），当我们调用`getImageData`或者`putImageData`时本质都是GPU显存和CPU内存的读写数据，这是个比较耗费性能的操作。如果我们的Canvas存在很频繁的这类读写操作，可以考虑使用`willReadFrequently`标识，这样Canvas的绘制数据都会被存储在CPU内存中，减少读写操作的延时，但同时也会失去GPU硬件加速的能力。

``` js
const ctx = canvas.getContext('2d', {
  willReadFrequently: true
})
```

> **willReadFrequently**
> 
> A boolean value that indicates whether or not a lot of read-back operations are planned. This will force the use of a software (instead of hardware accelerated) 2D canvas and can save memory when calling getImageData() frequently.
:::


### OffscreenCanvas
我们的主页面存在着互斥的JS线程（通常也被称为主线程）和渲染线程。每当主线程执行完一个JS任务，就会切到渲染线程执行渲染任务（即屏幕内容的绘制），绘制完后又回到主线程执行下一个JS任务。
这也是为什么长任务会导致页面卡顿，一般为了保证画面稳定在60帧的刷新率，我们需要每16.6秒绘制一次，但考虑到渲染线程本身的执行也是需要时间的，所以最终留给我们的每个JS任务的执行时间是比这更短的。

一般对于**前后依赖的长时间JS同步任务**，有种优化手段是利用如`setTimeout`或者`Promise.then`的能力把任务拆分成多个任务来异步执行（JS中的异步指的是单线程异步），从而避免任务过长导致页面卡顿。但任务整体的耗时是不会减少的（甚至更长了）。

而对于**互相独立的同步任务（JS任务或者渲染任务）**，我们可以借助Web Worker的能力实现并行的计算和渲染。
Web Worker都有着自己的JS线程和渲染线程，它们的执行不会影响到我们主页面的执行和渲染。而为了利用到Web Worker的渲染线程，我们需要使用到Canvas，然而不幸的是Web Worker环境下无法访问到DOM元素，为了解决这个问题浏览器在Web Worker下提供了和DOM完全接耦的Canvas————OffscreenCanvas。

在上文中我们也简单提到过OffscreenCanvas，它本身的绘制能力和普通的Canvas基本一致，并没有神奇的魔法来提升我们的绘制性能。能够在Web Worker下执行，充分利用Web Worker的渲染线程能力，使它最大的亮点。比如我们可以使用下文将要介绍的`transferControlToOffscreen`，实现通过Web Worker的渲染线程绘制主页面的内容。

:::info 并行处理
Web Worker提供给我们并行计算和渲染的能力，当我们存在特别多互相独立的任务时，理论上我们可以创建无数个Web Worker来实现并行加速。但实际上Web Worker的创建开销是不小的（进程级别），所以并不现实。我们一般会借助GPU的能力，来处理各种并行计算的复杂场景。
:::

#### transferControlToOffscreen
在主线程调用Canvas的`transferControlToOffscreen`方法可以生成一个OffscreenCanvas实例，同时会把自身上下文的所有权转移给该实例。

这意味着我们将无法直接访问Canvas的上下文，但通过OffscreenCanvas却可以拿到Canvas的上下文。而我们可以把OffscreenCanvas传递给Web Worker，即可通过在Web Woker中调用OffscreenCanvas的能力来间接绘制主线程的Canvas。

``` js title="main.js"
const canvas = document.createElement('canvas')
canvas.width = 5000
canvas.height = 5000
document.body.appendChild(canvas)

const offscreenCanvas = canvas.transferControlToOffscreen()
const worker = new Worker('./worker.js')
worker.postMessage({ canvas: offscreenCanvas }, [offscreenCanvas])
``` 


``` js title="worker.js"
let canvas = null;
self.onmessage = function(evt) {
    if (evt.data.canvas) {
        canvas = evt.data.canvas;
        draw()
    }
}

function draw() {
    if (canvas) {
        const ctx = canvas.getContext('2d');
        ctx.fillStyle = 'pink'
        ctx.fillRect(0, 0, canvas.width, canvas.height);
        requestAnimationFrame(draw)
    }
}
```

#### transferToImageBitmap
除了上述的方法外，我们也可以直接在Web Worker中初始化OffscreenCanvas实例并进行绘制操作。而为了将绘制内容同步到主线程的Canvas上，我们首先可能会想到`getImageData`但很明显这太耗性能了，又或者把OffscreenCanvas传递到主线程但我Worker线程后面还要用到所以也不行。因此浏览器给OffscreenCanvas提供了`transferToImageBitmap`的能力来解决这个问题。

在前述章节中我们介绍过，`getImageData`的本质是把GPU显存中的数据写入到CPU内存中，存在不小的性能开销。而`transferToImageBitmap`可以简单理解成GPU显存到GPU显存的传递，即把OffscreenCanvas当前绘制的内容转移到另一块GPU显存空间中，性能是比较好的，并且此时如果再尝试通过`getImageData`读取OffscreenCanvas的数据会发现都已经被重置了。


### ImageBitmap

#### createImageBitMap
``` js
const image = new Image();
image.src = '';
image.onload = function() {
  createImageBitmap(image).then(bitMap => {
    ctx.drawImage(bitMap, 0, 0);
  })
}
```


### 渲染引擎

#### 异步批量渲染

类似React中的`setState`，修改数据后会在下一个tick再进行渲染。

``` js
// konva实现
function batchDraw() {
    if (!this._waitingForDraw) {
      this._waitingForDraw = true;
      window.requestAnimFrame(() => {
        this.draw();
        this._waitingForDraw = false;
      });
    }
    return this;
}
```

#### 离屏渲染

当我们谈论到离屏渲染的技术，总是容易和OffscreenCanvas搞混淆。事实上，OffscreenCanvas的作用就是为了让我们在Web Worker这类的环境下使用Canvas的能力，如果我们单纯在主线程使用OffscreenCanvas，这和直接使用Canvas基本没有区别。

而所谓的离屏渲染，一般指的是我们除了在文档中用于绘制内容的Canvas外，额外创建新的Canvas来缓存绘制的内容。比如当某个虚拟节点要绘制的内容始终不变时，我们可以直接使用DrawImage来把离屏Canvas的内容进行绘制，从而省去了调用Canvas API来重复绘制相同内容的情况，实现性能的优化。



#### 分层渲染

可以使用多个Canvas进行渲染，比如把静态的内容和动态的内容进行分离。



#### 局部渲染/脏区检测

一般我们每次渲染时都会通过`clearRect`将画布的内容清空并进行全量绘制，一些渲染库中允许我们只重新渲染部分的内容实现性能优化。



#### 包围盒与碰撞检测

- AABB包围盒
- OBB包围盒
- 分离轴定律

#### 事件机制

- 取色值法
  - 实现简单；适合不规则图形
  - 需要额外绘制一份Canvas
- 几何法（引射线法）
  - 实现和计算复杂；适合规则图形



#### 布局系统

实现类似Flex的布局能力。



### API

#### 矩形绘制

- `fillRect()`
- `strokeRect()`
- `clearRect()`



#### 路径绘制

路径即为多个点的连线。

``` js
ctx.beginPath()

ctx.fill()
ctx.stroke()

ctx.closePath()
```



#### 坐标变换

- `ctx.translate(x, y)`
- `ctx.rotate(radians)`。将坐标系顺时针旋转，弧度制比如`ctx.rotate(Math.PI)`
- `ctx.scale(x, y)`
- `ctx.transform(a, b, c, d, e, f)`



#### save/restore

Canvas的2D上下文的本质是一个状态机，因此它还提供了保存和恢复当前状态的能力。

``` js
ctx.save()
ctx.tranlate(10, 10)
ctx.fillRect(0, 0, 100, 100)
ctx.restore()
```







### 性能优化

- 减少上下文切换





## WebGL

浏览器所提供的WebGL给予了我们图形绘制的能力，WebGL本质上基于OpenGL ES2.0，而后者实际上是OpenGL的一个精简子集，缺少了一部分的能力（如几何着色器等）。

近年来WebGL2的实现也逐渐稳定，它基于OpenGL ES3.0。

``` js
const canvas = document.querySelector('canvas');
const webgl = canvas.getContext('webgl');
const webgl2 = canvas.getContext('webgl2');
```



### 渲染管线

1. CPU准备工作。着色器的编译、链接；顶点数据、顶点颜色、顶点UV坐标、顶点法线等数据的写入；纹理数据的写入等。

2. 顶点着色器。逐顶点执行，我们的顶点数据通常由3D建模软件导出，我们会先通过**模型矩阵Model**将模型空间转变为世界空间，再通过**视图矩阵View**将世界空间转变为观察空间，再通过**投影矩阵Projection（透视投影或正交投影）**转变为**齐次裁剪空间（Clip Space）**。以上的变换统称MVP变化。裁剪空间中坐标的XYZ三维都位于[-1,1]之间，W分量通常为1。后续（在第三步裁剪之后）GPU内部会通过**透视除法**将四维顶点转化成三维的**标准化设备坐标（NDC）**。

   ![](https://img-blog.csdn.net/20171229111837073?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYmllemhpaHVh/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

3. 图元装配、裁剪。根据指令将顶点组装成图元（线、三角形），并把齐次裁剪空间外的内容剔除。

4. 光栅化。

   ![img](https://img-blog.csdnimg.cn/b26e74a5ee5b4f8781cbe684ac25ebaa.png)

5. 片元着色器。GPU会将通过**视口变化**将NDC坐标转化成**屏幕空间（Screen Space）**坐标，并传入给片元着色器的`gl_FragCoord`。片元着色器逐屏幕像素执行，通常在此时实现滤镜（如通过LUT）或后处理（各种特效、模糊、边缘检测），最终将数据写入帧缓冲（显存）中。

6. 深度测试





### OpenGL Shading Language（GLSL）

#### Vertex Shader

``` glsl
// vertex shader 顶点着色器
attribute vec2 a_position;

void main() {
  gl_Position = vec4(a_position, 0.0, 1.0);
}
```
![vs](https://images2018.cnblogs.com/blog/669331/201803/669331-20180302113903143-870412752.png)



#### Fragment Shader

``` glsl
// fragment shader 片段着色器/像素着色器
precision mediump float;

void main() {
  gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0); 
}
```
![fs](https://img-blog.csdn.net/20140917135608231)

#### atrribute

通常我们通过CPU将顶点坐标、颜色/UV、法向量写入GPU的显存当中，CPU的每个线程/管道会逐个读取（因此对于不同的线程，该值通常是不同的）对应的数据交给**顶点着色器Vertex Shade**，这些值通常用`attribute`声明。



#### uniform

同样也是通过CPU写入，但`uniform`可以被顶点着色器以及片段着色器访问，另外对于不同GPU线程来说该值是相同的。



#### varying

该值通常在顶点着色器中定义和赋值，后续对应的片段着色器中可以取到对应的值。插值。





#### 数据类型

#### 内置函数

- `abs(x)`，绝对值。
- `floor(x)`，获取整数部分。
- `fract(x)`，获取小数部分。
- `ceil(x)`，向上取整。
- `max(x, y)`，`min(x, y)`，`clamp(x, min, max)`
- `mix(a, b, t)`，混合（线性组合），`mix(a, b, t)`表示`a * (1 - t) + b * (t)`。
- `step(edge, x)`，当`x`小于`edge`时返回0，否则返回1。
- `smoothstep(edge0, edge1, x)`，当`x`小于`edge0`时返回0，当`x`大于`edge0`时返回1，否则返回的值为`edge0`到`edge1`的插值。
- `length(vec)`，返回向量的长度。





#### 纹理（Texture）、UV坐标与采样

把一张图片作为Texture纹理，图片左下角为(0, 0)，右上角为(1, 1)，可以通过UV坐标来进行采样。





#### drawArrays

`wegl`的实际绘制指令，我们实际上是绘制无数个顶点，绘制线段或三角形，本质上是在点与点之间进行线性插值。

``` js
gl.drawArrays(gl.POINTS, 0, 3) // 绘制三个顶点

gl.drawArrays(gl.LINES, 0, 2) // 绘制两个顶点，两个顶点之间的内容通过线性插值，因此最终看到的是线段

gl.drawArrays(gl.TRIANGLES, 0, 3) // 绘制三个顶点，三个顶点之间的内容通过线性插值，因此最终看到的是三角形

// 先绘制buffer中前三个顶点，再绘制后三个顶点，总共六个
gl.drawArrays(gl.TRIANGLES, 0, 3)
gl.drawArrays(gl.TRIANGLES, 3, 3)

```



### 随机数和噪声

噪声在图形学中存在着许多的应用，比如可以实现故障艺术。通常我们会借助随机数来生成噪声图，GLSL内置了`rand`这一确定性随机（即伪随机），但通常我们会自己实现一个伪随机函数。

``` glsl
y = fract(sin(x)*10000.0);
```

为了从二维向量生成随机数，以上的式子又可以被扩展成如下，式子中的魔法数字是经过实践后被广泛使用的数字。

``` glsl
float random (vec2 st) {
    return fract(sin(dot(st.xy, vec2(12.9898, 78.233))) * 43758.5453123);
}
```



### 混合模式

#### 溶解

> TODO





### 模糊效果

> 高斯模糊







### 线性代数

#### 向量

- 向量相加
- 向量数乘
- 向量内积（点积），得到标量
- 向量外积（乘积），得到向量
- 向量的线性组合（常见的组合如线性插值）

#### 矩阵

- 矩阵加法
- 矩阵乘法（向量的线性组合）



### Trouble Shooting

1. Shader代码记得加分号。

2. Shader代码中数字记得小数点。

3. 顶点顺序逆时针。

4. 图像绘制反了。

   ``` glsl
   this.gl.pixelStorei(this.gl.UNPACK_FLIP_Y_WEBGL, true);
   ```

5. 图像绘制黑屏，纹理宽高需要是二的幂。

   ``` glsl
   this.gl.texParameteri(
     this.gl.TEXTURE_2D,
     this.gl.TEXTURE_MIN_FILTER,
     this.gl.LINEAR
   );
   this.gl.texParameteri(
     this.gl.TEXTURE_2D,
     this.gl.TEXTURE_WRAP_S,
     this.gl.CLAMP_TO_EDGE
   );
   this.gl.texParameteri(
     this.gl.TEXTURE_2D,
     this.gl.TEXTURE_WRAP_T,
     this.gl.CLAMP_TO_EDGE
   );
   ```

6. WebGL内置8个纹理单元，绑定多个纹理时需要提前激活。

   ``` glsl
   gl.activeTexture(gl.TEXTURE0);
   ```

   











### 参考链接

1. https://juejin.cn/post/6891918137671811079

2. https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API/Tutorial
3. https://shaderific.com/glsl/common_functions.html
4. https://en.wikipedia.org/wiki/Blend_modes
